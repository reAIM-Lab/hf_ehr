
---

# ğŸ©º Context Clues: Linear Probing for EHR Embeddings

This code performs **linear probing** using precomputed **embedding representations of patient health records** to evaluate downstream task performance across different phenotype prediction tasks (e.g., AMI, T2DM). It supports embeddings generated by foundation models (e.g., Mamba-EHRShot) and evaluates classification accuracy using logistic regression trained with **PyTorch Lightning**.

---

## ğŸš€ Usage

```bash
python main.py \
  --input_meds /path/to/meds/dataset \
  --task AMI \
  --model mamba-tiny-4096-clmbr \
  --model_type mamba-ehrshot \
  --seed 123
```

If running all tasks at once, and generating metrics (needs to have Vincent's MEDS-eval branch installed to run)

```bash
./phenotype_predictions.sh
```

### Arguments

| Argument        | Default | Description                                                                 |
|-----------------|---------|-----------------------------------------------------------------------------|
| `--input_meds`  | `/data2/...` | Path to the processed dataset containing embeddings and label files         |
| `--task`        | `AMI`   | Name of the task (e.g., AMI, T2DM, etc.)                                    |
| `--model`       | `mamba-tiny-4096-clmbr` | Model identifier used for Huggingface                        |
| `--model_type`  | `mamba-ehrshot` | Label used for storing embeddings, saving predictions                 |
| `--seed`        | `123`   | Random seed for reproducibility                                              |

---

## ğŸ“ File Structure

```
.
â”œâ”€â”€ utils.py                # Contains helper functions and LR model definition
â”œâ”€â”€ main.py     # Main script
â”œâ”€â”€ models/
â”‚   â””â”€â”€ <task_name>/        # Stores trained models for each task
â”œâ”€â”€ predictions/
â”‚   â””â”€â”€ <task_name>/        # Stores prediction outputs
â”œâ”€â”€ checkpoints/            # Stores temporary model checkpoints
```

---

## ğŸ“Š Output

For each task and training size (1K, 10K, 100K), the following is saved:
- Trained model weights at: `models/<task_name>/linear_probing_<size>.pth`
- Prediction outputs (with probabilities and binary outcomes) at:  
  `predictions/<task_name>/<model_type>_<size>.parquet`

Each prediction file contains:
- `subject_id`
- `prediction_time`
- `boolean_value` (ground truth)
- `predicted_boolean_value`
- `predicted_boolean_probability`

---

## ğŸ§ª Supported Tasks

Currently, the following phenotype tasks are supported via in-house cohorts:

- AMI
- Celiac
- CLL
- HTN
- Ischemic_Stroke
- MASLD
- Osteoporosis
- Pancreatic_Cancer
- SLE
- T2DM

---

## ğŸ› ï¸ Notes

- The MEDS data is loaded from:
  - `post_transform/data/train/`
  - `post_transform/data/tuning/`
  - `post_transform/data/held_out/`
- Adapt `utils.py` if using a different model (Change global `BATCH_SIZE` and `CONTEXT_LENGTH` parameters).
