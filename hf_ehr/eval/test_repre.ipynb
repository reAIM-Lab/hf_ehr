{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       subject_id            prediction_time  boolean_value  \\\n",
      "0             971 2009-02-06 14:53:00.250199              0   \n",
      "1             971 2009-05-02 12:29:00.250349              0   \n",
      "2             971 2009-06-20 14:02:00.250609              0   \n",
      "3             971 2009-06-28 14:03:00.250609              0   \n",
      "4             971 2013-04-14 09:30:00.000000              0   \n",
      "...           ...                        ...            ...   \n",
      "49995    15615820 2022-01-31 15:14:06.000000              0   \n",
      "49996    15615820 2022-02-14 13:00:00.000000              0   \n",
      "49997    15619505 2022-12-18 10:36:53.000000              0   \n",
      "49998    15623225 2021-05-25 10:46:30.000000              0   \n",
      "49999    15623225 2022-06-20 10:29:44.000000              0   \n",
      "\n",
      "                                                features  \n",
      "0      [-1.5571088, -0.6172047, 1.2579645, 0.30174413...  \n",
      "1      [-1.246936, -0.7224043, 1.2480731, 0.20652555,...  \n",
      "2      [-1.229949, -0.69501644, 1.1290375, 0.41305855...  \n",
      "3      [-0.8467767, -0.8494273, 0.8178067, 0.4560932,...  \n",
      "4      [0.05599575, -0.08075702, 0.712411, 0.28072417...  \n",
      "...                                                  ...  \n",
      "49995  [0.8311657, 1.3242878, 1.6580124, 0.872197, 0....  \n",
      "49996  [1.0993247, 1.292082, 1.5542529, 0.4077765, 0....  \n",
      "49997  [0.4969197, -0.47375384, -0.64790905, 2.114496...  \n",
      "49998  [-0.53501, 2.6930149, -0.4255028, 2.1799676, 1...  \n",
      "49999  [-0.29621747, 2.9119508, -0.14436722, 1.824594...  \n",
      "\n",
      "[50000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "train_file_name = \"train.parquet\"\n",
    "test_file_name = \"test.parquet\"\n",
    "motor_data_dir = \"/data/processed_datasets/processed_datasets/ehr_foundation_data/ohdsi_cumc_deid/ohdsi_cumc_deid_2023q4r3_v3_mapped/models/femr/motor_large_no_visit_id_8192/results/AMI/motor_730/features_with_label\"\n",
    "train_parquet = pd.read_parquet(Path(motor_data_dir)/train_file_name)\n",
    "test_parquet = pd.read_parquet(Path(motor_data_dir)/test_file_name)\n",
    "# print(train_parquet)\n",
    "print(test_parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[✓] Celiac: train updated, tune deleted, testing → test\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# ─── CONFIGURE ────────────────────────────────────────────────────────────────\n",
    "base_dir    = \"/data/processed_datasets/processed_datasets/ehr_foundation_data/ohdsi_cumc_deid/ohdsi_cumc_deid_2023q4r3_v3_mapped/llama\"                  # ← change this\n",
    "# task_labels = [\"AMI\",\"CLL\",\"HTN\", \"Ischemic_Stroke\", \"MASLD\", \"Osteoporosis\", \"Pancreatic_Cancer\" ,\"SLE\" ,\"T2DM\"]     # ← your list of task sub-dirs\n",
    "task_labels=[\"Celiac\"]\n",
    "# ───────────────────────────────────────────────────────────────────────────────\n",
    "\n",
    "for task_label in task_labels:\n",
    "    p = Path(base_dir) / task_label / \"features_with_label\"\n",
    "\n",
    "    train_path   = p / \"train.parquet\"\n",
    "    tune_path    = p / \"tune.parquet\"\n",
    "    testing_path = p / \"testing.parquet\"\n",
    "    new_test     = p / \"test.parquet\"\n",
    "\n",
    "    # 1) load\n",
    "    df_train = pd.read_parquet(train_path)\n",
    "    df_tune  = pd.read_parquet(tune_path)\n",
    "\n",
    "    # 2) concat & sort\n",
    "    df = pd.concat([df_train, df_tune], ignore_index=True)\n",
    "    df = df.sort_values(by=[\"subject_id\", \"prediction_time\"])\n",
    "\n",
    "    # 3) overwrite train.parquet\n",
    "    df.to_parquet(train_path, index=False)\n",
    "\n",
    "    # 4) delete tune.parquet\n",
    "    if tune_path.exists():\n",
    "        tune_path.unlink()\n",
    "\n",
    "    # 5) rename testing.parquet → test.parquet\n",
    "    if testing_path.exists():\n",
    "        testing_path.rename(new_test)\n",
    "\n",
    "    print(f\"[✓] {task_label}: train updated, tune deleted, testing → test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (100_000, 4)\n",
      "┌────────────┬────────────────────────────┬───────────────┬─────────────────────────────────┐\n",
      "│ subject_id ┆ prediction_time            ┆ boolean_value ┆ features                        │\n",
      "│ ---        ┆ ---                        ┆ ---           ┆ ---                             │\n",
      "│ i64        ┆ datetime[ns]               ┆ i64           ┆ list[f32]                       │\n",
      "╞════════════╪════════════════════════════╪═══════════════╪═════════════════════════════════╡\n",
      "│ 610        ┆ 2015-01-04 11:00:00        ┆ 0             ┆ [1.23367, -0.172913, … -0.5061… │\n",
      "│ 610        ┆ 2015-02-09 09:00:00        ┆ 0             ┆ [1.244484, 0.442903, … -0.2181… │\n",
      "│ 610        ┆ 2015-02-17 12:36:00.100270 ┆ 0             ┆ [0.370727, 0.445867, … -0.7110… │\n",
      "│ 610        ┆ 2015-02-23 12:00:00.100310 ┆ 0             ┆ [0.969827, 0.637445, … -0.4157… │\n",
      "│ 610        ┆ 2015-04-05 09:00:00        ┆ 0             ┆ [0.515411, 0.63285, … -0.19573… │\n",
      "│ …          ┆ …                          ┆ …             ┆ …                               │\n",
      "│ 15624238   ┆ 2007-04-16 10:12:00.026099 ┆ 0             ┆ [1.301916, 1.015666, … -0.5625… │\n",
      "│ 15624238   ┆ 2007-05-04 15:13:00.026119 ┆ 0             ┆ [0.203977, 0.600254, … 0.03169… │\n",
      "│ 15624238   ┆ 2010-06-14 08:09:00.026439 ┆ 0             ┆ [0.940321, 0.339506, … -0.0522… │\n",
      "│ 15624238   ┆ 2010-06-23 15:46:00.026459 ┆ 0             ┆ [-0.12487, -0.221407, … -0.446… │\n",
      "│ 15624238   ┆ 2016-07-26 13:00:00        ┆ 0             ┆ [0.060561, -0.653808, … 0.7363… │\n",
      "└────────────┴────────────────────────────┴───────────────┴─────────────────────────────────┘\n",
      "shape: (50_000, 4)\n",
      "┌────────────┬────────────────────────────┬───────────────┬─────────────────────────────────┐\n",
      "│ subject_id ┆ prediction_time            ┆ boolean_value ┆ features                        │\n",
      "│ ---        ┆ ---                        ┆ ---           ┆ ---                             │\n",
      "│ i64        ┆ datetime[ns]               ┆ i64           ┆ list[f32]                       │\n",
      "╞════════════╪════════════════════════════╪═══════════════╪═════════════════════════════════╡\n",
      "│ 971        ┆ 2009-02-06 14:53:00.250199 ┆ 0             ┆ [0.443637, 0.003294, … -0.0041… │\n",
      "│ 971        ┆ 2009-05-02 12:29:00.250349 ┆ 0             ┆ [0.256534, 0.936439, … -0.7395… │\n",
      "│ 971        ┆ 2009-06-20 14:02:00.250609 ┆ 0             ┆ [0.091052, -0.509081, … 0.4015… │\n",
      "│ 971        ┆ 2009-06-28 14:03:00.250609 ┆ 0             ┆ [-0.214993, -0.054808, … 0.292… │\n",
      "│ 971        ┆ 2013-04-14 09:30:00        ┆ 0             ┆ [1.401207, 0.938882, … -0.6265… │\n",
      "│ …          ┆ …                          ┆ …             ┆ …                               │\n",
      "│ 15615820   ┆ 2022-01-31 15:14:06        ┆ 0             ┆ [0.528591, 0.675411, … 0.73924… │\n",
      "│ 15615820   ┆ 2022-02-14 13:00:00        ┆ 0             ┆ [0.703636, 1.713484, … -0.3126… │\n",
      "│ 15619505   ┆ 2022-12-18 10:36:53        ┆ 0             ┆ [0.200786, 1.42789, … -1.48565… │\n",
      "│ 15623225   ┆ 2021-05-25 10:46:30        ┆ 0             ┆ [1.134616, -0.188159, … 0.1776… │\n",
      "│ 15623225   ┆ 2022-06-20 10:29:44        ┆ 0             ┆ [1.003584, -0.252371, … 0.3969… │\n",
      "└────────────┴────────────────────────────┴───────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# raw_data_dir = \"/data/processed_datasets/processed_datasets/ehr_foundation_data/ohdsi_cumc_deid/ohdsi_cumc_deid_2023q4r3_v3_mapped/task_labels/phenotype_sample/AMI\"\n",
    "# train_data_parquet = pd.read_parquet(Path(raw_data_dir)/train_file_name)\n",
    "# print(train_data_parquet)\n",
    "\n",
    "# tune_data_parquet = pd.read_parquet(Path(raw_data_dir)/tune_file_name)\n",
    "# print(tune_data_parquet)\n",
    "import polars as pl\n",
    "import torch\n",
    "import numpy as np\n",
    "base_dir = \"/data/processed_datasets/processed_datasets/ehr_foundation_data/ohdsi_cumc_deid/ohdsi_cumc_deid_2023q4r3_v3_mapped/mamba/AMI/features_with_label\"\n",
    "train_path = Path(base_dir)/\"train.parquet\"\n",
    "# tune_path = Path(base_dir)/\"tune.parquet\"\n",
    "test_path = Path(base_dir)/\"test.parquet\"\n",
    "train_df = pl.read_parquet(train_path)\n",
    "test_df = pl.read_parquet(test_path)\n",
    "print(train_df)\n",
    "print(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# raw_data_dir = \"/data/processed_datasets/processed_datasets/ehr_foundation_data/ohdsi_cumc_deid/ohdsi_cumc_deid_2023q4r3_v3_mapped/post_transform/data/train\"\n",
    "# # raw_outcome = \"/data/processed_datasets/processed_datasets/ehr_foundation_data/ohdsi_cumc_deid/ohdsi_cumc_deid_2023q4r3_v3_mapped/task_labels/patient_outcomes_sample/readmission\"\n",
    "# for file in sorted(Path(raw_data_dir).glob(\"*.parquet\")):\n",
    "#     print(file,Path(file).stem)\n",
    "\n",
    "\n",
    "a = 124.1313\n",
    "print(int(a))\n",
    "\n",
    "# train_data_parquet = pd.read_parquet(Path(raw_data_dir)/\"0.parquet\")\n",
    "# raw_path =  pd.read_parquet(Path(raw_outcome)/\"train.parquet\")\n",
    "# print(raw_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
