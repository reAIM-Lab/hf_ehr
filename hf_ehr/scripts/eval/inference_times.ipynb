{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>context_length</th>\n",
       "      <th>mean_inference_time_seconds</th>\n",
       "      <th>throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>3.466146</td>\n",
       "      <td>12.309543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>1.960118</td>\n",
       "      <td>43.534793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>1.969450</td>\n",
       "      <td>86.657002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>1.987233</td>\n",
       "      <td>171.763103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.011993</td>\n",
       "      <td>339.298686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>3.304645</td>\n",
       "      <td>103.288969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>3.590669</td>\n",
       "      <td>190.122421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>4.139411</td>\n",
       "      <td>329.837608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>5.218785</td>\n",
       "      <td>523.237971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>7.312505</td>\n",
       "      <td>746.848540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name  context_length  mean_inference_time_seconds  throughput\n",
       "0       mamba            1024                     3.466146   12.309543\n",
       "1       mamba            1024                     1.960118   43.534793\n",
       "2       mamba            1024                     1.969450   86.657002\n",
       "3       mamba            1024                     1.987233  171.763103\n",
       "4       mamba            1024                     2.011993  339.298686\n",
       "..        ...             ...                          ...         ...\n",
       "27       gpt2            4096                     3.304645  103.288969\n",
       "28       gpt2            4096                     3.590669  190.122421\n",
       "29       gpt2            4096                     4.139411  329.837608\n",
       "30       gpt2            4096                     5.218785  523.237971\n",
       "31       gpt2            4096                     7.312505  746.848540\n",
       "\n",
       "[88 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_hyena = pd.read_csv('inference_times_hyena.csv')\n",
    "df_mamba = pd.read_csv('inference_times_mamba.csv')\n",
    "df_llama = pd.read_csv('inference_times_llama.csv')\n",
    "df_gpt = pd.read_csv('inference_times_gpt.csv')\n",
    "\n",
    "df = pd.concat([df_mamba, df_llama, df_gpt])\n",
    "df['throughput']  = df['batch_size'] * df['num_tokens_to_generate'] / df['inference_time_seconds']\n",
    "df = df[['model_name', 'context_length', 'mean_inference_time_seconds', 'throughput']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: new_hypertension\n",
      "Processing task: guo_los\n",
      "Processing task: lab_hypoglycemia\n",
      "Processing task: new_lupus\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: lab_hyponatremia\n",
      "Processing task: new_pancan\n",
      "Processing task: lab_anemia\n",
      "Processing task: new_acutemi\n",
      "Processing task: guo_readmission\n",
      "Processing task: lab_thrombocytopenia\n",
      "Processing task: new_hyperlipidemia\n",
      "Processing task: new_celiac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing task: lab_hyperkalemia\n",
      "Processing task: guo_icu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
      "/tmp/ipykernel_1409374/3994874447.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['model'] = df['model'].str.split('--clmbr_train').str[0]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Dictionary mapping folder names to actual task names\n",
    "folder_to_name_mapping = {\n",
    "    'guo_los': 'Long LOS',\n",
    "    'guo_icu': 'ICU Prediction',\n",
    "    'guo_readmission': '30-Day Readmission',\n",
    "    'lab_anemia': 'Anemia',\n",
    "    'lab_hyperkalemia': 'Hyperkalemia',\n",
    "    'lab_hypoglycemia': 'Hypoglycemia',\n",
    "    'lab_hyponatremia': 'Hyponatremia',\n",
    "    'lab_thrombocytopenia': 'Thrombocytopenia',\n",
    "    'new_acutemi': 'Acute MI',\n",
    "    'new_celiac': 'Celiac',\n",
    "    'new_hyperlipidemia': 'Hyperlipidemia',\n",
    "    'new_hypertension': 'Hypertension',\n",
    "    'new_lupus': 'Lupus',\n",
    "    'new_pancan': 'Pancreatic Cancer',\n",
    "    'chexpert': 'Chexpert'\n",
    "}\n",
    "\n",
    "\n",
    "# Function to clean and extract relevant information from the CSV\n",
    "def clean_and_extract(df):\n",
    "    # Select and clean relevant columns, including the replicate column and bounds\n",
    "    df = df[['sub_task', 'model', 'k', 'score', 'value', 'replicate', 'lower', 'upper']]\n",
    "    df['model'] = df['model'].str.split('--clmbr_train').str[0]\n",
    "    \n",
    "    # Filter for AUROC scores\n",
    "    df = df[(df['k'] == -1) & (df['score'] == 'auroc')]\n",
    "    \n",
    "    # Extract architecture and context length\n",
    "    df['architecture'] = df['model'].apply(lambda x: x.split('-')[0])\n",
    "    \n",
    "    # Exclude BERT from the data\n",
    "    df = df[df['architecture'] != 'bert']\n",
    "    \n",
    "    # Extract context length safely and ensure it's an integer\n",
    "    df['context_length'] = df['model'].apply(lambda x: int(x.split('-')[2]) if len(x.split('-')) > 2 and x.split('-')[2].isdigit() else None)\n",
    "    \n",
    "    # Filter out rows related to GPT vocab size variations\n",
    "    df = df[~df['model'].str.contains('--clmbr-')]\n",
    "    \n",
    "    # Group by task, model, architecture, context length, and calculate mean and bounds for replicates\n",
    "    df_grouped = df.groupby(['sub_task', 'model', 'architecture', 'context_length']).agg(\n",
    "        value_mean=('value', 'mean'),\n",
    "        lower_bound=('lower', 'mean'),\n",
    "        upper_bound=('upper', 'mean')\n",
    "    ).reset_index()\n",
    "    \n",
    "    return df_grouped\n",
    "    \n",
    "# Function to process all tasks and return the combined summary\n",
    "def process_all_tasks_for_plotting():\n",
    "    ehrshot_dir = '/share/pi/nigam/users/migufuen/ehrshot-benchmark/EHRSHOT_ASSETS/results_ehrshot'  # Point to the 'ehrshot' directory\n",
    "    combined_summary = pd.DataFrame()\n",
    "    include_models = [\n",
    "        'gpt2-base-512--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'gpt2-base-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'gpt2-base-2048--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'gpt2-base-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'hyena-large-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'hyena-large-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'hyena-large-8192--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'hyena-large-16384--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'llama-base-512--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'llama-base-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'llama-base-2048--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'llama-base-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'mamba-tiny-1024--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'mamba-tiny-4096--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'mamba-tiny-8192--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last',\n",
    "        'mamba-tiny-16384--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "        'mamba-tiny-32768--clmbr_train-tokens-total_nonPAD-ckpt_val=2000000000-persist_chunk:last_embed:last', \n",
    "    ]\n",
    "    \n",
    "    exclude_tasks = [\n",
    "        'chexpert'\n",
    "    ]\n",
    "    for task_name in os.listdir(ehrshot_dir):\n",
    "        task_path = os.path.join(ehrshot_dir, task_name)\n",
    "        if os.path.isdir(task_path) and task_name not in exclude_tasks:\n",
    "                try:\n",
    "                    print(f\"Processing task: {task_name}\")\n",
    "                    # Read and clean data\n",
    "                    input_file = os.path.join(task_path, 'all_results.csv')\n",
    "                    df = pd.read_csv(input_file)\n",
    "                    df = df[df['model'].isin(include_models)]\n",
    "                    df_cleaned = clean_and_extract(df)\n",
    "                    df_cleaned['task_name'] = folder_to_name_mapping.get(task_name, task_name)\n",
    "                    \n",
    "                    # Map the task name to a human-readable name\n",
    "                    if task_name == 'chexpert':\n",
    "                        df_cleaned = df_cleaned.groupby(['architecture', 'context_length', 'model', 'task_name']).agg({\n",
    "                            'value_mean': 'mean',\n",
    "                            'lower_bound': 'mean',\n",
    "                            'upper_bound': 'mean'\n",
    "                        }).reset_index()\n",
    "                        df_cleaned['sub_task'] = df_cleaned['task_name']\n",
    "                    \n",
    "                    \n",
    "                    # Combine with the overall summary\n",
    "                    combined_summary = pd.concat([combined_summary, df_cleaned], ignore_index=True)\n",
    "                    # print(combined_summary.head())  # Debug: Inspect the first few rows\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Failed to process task {task_name}: {e}\")\n",
    "    return combined_summary\n",
    "\n",
    "combined_summary = process_all_tasks_for_plotting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>context_length</th>\n",
       "      <th>value_mean</th>\n",
       "      <th>model_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2-base-1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.783288</td>\n",
       "      <td>gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2-base-2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.799709</td>\n",
       "      <td>gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2-base-4096</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.791480</td>\n",
       "      <td>gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2-base-512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.792351</td>\n",
       "      <td>gpt2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hyena-large-1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.794380</td>\n",
       "      <td>hyena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hyena-large-16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.731876</td>\n",
       "      <td>hyena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hyena-large-4096</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.796362</td>\n",
       "      <td>hyena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>hyena-large-8192</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.766145</td>\n",
       "      <td>hyena</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama-base-1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.789721</td>\n",
       "      <td>llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama-base-2048</td>\n",
       "      <td>2048</td>\n",
       "      <td>0.800335</td>\n",
       "      <td>llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>llama-base-4096</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.796923</td>\n",
       "      <td>llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>llama-base-512</td>\n",
       "      <td>512</td>\n",
       "      <td>0.788990</td>\n",
       "      <td>llama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>mamba-tiny-1024</td>\n",
       "      <td>1024</td>\n",
       "      <td>0.784284</td>\n",
       "      <td>mamba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>mamba-tiny-16384</td>\n",
       "      <td>16384</td>\n",
       "      <td>0.807706</td>\n",
       "      <td>mamba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>mamba-tiny-32768</td>\n",
       "      <td>32768</td>\n",
       "      <td>0.789466</td>\n",
       "      <td>mamba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>mamba-tiny-4096</td>\n",
       "      <td>4096</td>\n",
       "      <td>0.801870</td>\n",
       "      <td>mamba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mamba-tiny-8192</td>\n",
       "      <td>8192</td>\n",
       "      <td>0.798959</td>\n",
       "      <td>mamba</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  context_length  value_mean model_name\n",
       "0      gpt2-base-1024            1024    0.783288       gpt2\n",
       "1      gpt2-base-2048            2048    0.799709       gpt2\n",
       "2      gpt2-base-4096            4096    0.791480       gpt2\n",
       "3       gpt2-base-512             512    0.792351       gpt2\n",
       "4    hyena-large-1024            1024    0.794380      hyena\n",
       "5   hyena-large-16384           16384    0.731876      hyena\n",
       "6    hyena-large-4096            4096    0.796362      hyena\n",
       "7    hyena-large-8192            8192    0.766145      hyena\n",
       "8     llama-base-1024            1024    0.789721      llama\n",
       "9     llama-base-2048            2048    0.800335      llama\n",
       "10    llama-base-4096            4096    0.796923      llama\n",
       "11     llama-base-512             512    0.788990      llama\n",
       "12    mamba-tiny-1024            1024    0.784284      mamba\n",
       "13   mamba-tiny-16384           16384    0.807706      mamba\n",
       "14   mamba-tiny-32768           32768    0.789466      mamba\n",
       "15    mamba-tiny-4096            4096    0.801870      mamba\n",
       "16    mamba-tiny-8192            8192    0.798959      mamba"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mean = combined_summary.groupby(['model', 'context_length'])['value_mean'].mean().reset_index()\n",
    "df_mean['model_name'] = df_mean['model'].apply(lambda x: x.split('-')[0])\n",
    "df_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>context_length</th>\n",
       "      <th>throughput</th>\n",
       "      <th>ehrshot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>512</td>\n",
       "      <td>744.518766</td>\n",
       "      <td>0.792351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>1024</td>\n",
       "      <td>743.835151</td>\n",
       "      <td>0.783288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>2048</td>\n",
       "      <td>741.761030</td>\n",
       "      <td>0.799709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt2</td>\n",
       "      <td>4096</td>\n",
       "      <td>746.848540</td>\n",
       "      <td>0.791480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama</td>\n",
       "      <td>512</td>\n",
       "      <td>1156.818764</td>\n",
       "      <td>0.788990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>llama</td>\n",
       "      <td>1024</td>\n",
       "      <td>1157.053120</td>\n",
       "      <td>0.789721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>llama</td>\n",
       "      <td>2048</td>\n",
       "      <td>1791.947023</td>\n",
       "      <td>0.800335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama</td>\n",
       "      <td>4096</td>\n",
       "      <td>1795.433293</td>\n",
       "      <td>0.796923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mamba</td>\n",
       "      <td>1024</td>\n",
       "      <td>2205.268081</td>\n",
       "      <td>0.784284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>mamba</td>\n",
       "      <td>4096</td>\n",
       "      <td>2295.818796</td>\n",
       "      <td>0.801870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>mamba</td>\n",
       "      <td>8192</td>\n",
       "      <td>2297.365726</td>\n",
       "      <td>0.798959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mamba</td>\n",
       "      <td>16384</td>\n",
       "      <td>2289.140376</td>\n",
       "      <td>0.807706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   model_name  context_length   throughput   ehrshot\n",
       "0        gpt2             512   744.518766  0.792351\n",
       "1        gpt2            1024   743.835151  0.783288\n",
       "2        gpt2            2048   741.761030  0.799709\n",
       "3        gpt2            4096   746.848540  0.791480\n",
       "4       llama             512  1156.818764  0.788990\n",
       "5       llama            1024  1157.053120  0.789721\n",
       "6       llama            2048  1791.947023  0.800335\n",
       "7       llama            4096  1795.433293  0.796923\n",
       "8       mamba            1024  2205.268081  0.784284\n",
       "9       mamba            4096  2295.818796  0.801870\n",
       "10      mamba            8192  2297.365726  0.798959\n",
       "11      mamba           16384  2289.140376  0.807706"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = df.groupby(['model_name', 'context_length']).agg({\n",
    "    'throughput': 'max',\n",
    "}).reset_index()\n",
    "model2ehrshot = {\n",
    "    (row['model_name'], row['context_length']) : row['value_mean']\n",
    "    for idx, row in df_mean.iterrows()\n",
    "}\n",
    "df_['ehrshot'] = df_.apply(lambda row: model2ehrshot.get((row['model_name'], row['context_length']), None), axis=1)\n",
    "df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| model_name   |   context_length |   throughput |   ehrshot |\n",
      "|:-------------|-----------------:|-------------:|----------:|\n",
      "| gpt2         |              512 |      744.519 |  0.792351 |\n",
      "| gpt2         |             1024 |      743.835 |  0.783288 |\n",
      "| gpt2         |             2048 |      741.761 |  0.799709 |\n",
      "| gpt2         |             4096 |      746.849 |  0.79148  |\n",
      "| llama        |              512 |     1156.82  |  0.78899  |\n",
      "| llama        |             1024 |     1157.05  |  0.789721 |\n",
      "| llama        |             2048 |     1791.95  |  0.800335 |\n",
      "| llama        |             4096 |     1795.43  |  0.796923 |\n",
      "| mamba        |             1024 |     2205.27  |  0.784284 |\n",
      "| mamba        |             4096 |     2295.82  |  0.80187  |\n",
      "| mamba        |             8192 |     2297.37  |  0.798959 |\n",
      "| mamba        |            16384 |     2289.14  |  0.807706 |\n"
     ]
    }
   ],
   "source": [
    "print(df_.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
