# @package _global_

model:
  name: bert
  # Name/path to pass to HF.from_pretrained()
  hf_name: bert-base-uncased
  # If TRUE, then keep pretrained weights
  is_keep_pretrained_weights: False

# Default trainer
trainer:
  # For models that use MLM training, this is the percent of tokens to randomly mask
  mlm_mask_pct: 0.15

  optimizer:
    lr: 1e-4

  scheduler:
    num_warmup_steps: 40_000
    num_decay_steps: 4_000_000
    initial_lr: 3e-6
    final_lr: 3e-5

data:
  mlm_prob: 0.15